{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LSfGTJNuNQp0",
        "outputId": "80c3c025-5cb9-46f6-953c-37c92bf308fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.53.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Downloading streamlit-1.53.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.53.1\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit pandas numpy joblib scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e3bede8",
        "outputId": "30a23768-5b82-42b0-bc10-a08bff3de1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "#Import Libraries\n",
        "import os;\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "# 1. Set the Streamlit page configuration\n",
        "st.set_page_config(\n",
        "    page_title='Direct Marketing Campaigns on Portuguese Banking Data',\n",
        "    layout='wide'\n",
        ")\n",
        "\n",
        "# Color options for the background\n",
        "color_options = {\n",
        "    'Light Gray': 'lightgray',\n",
        "    'Light Cyan': 'lightcyan',\n",
        "    'Sky Blue': 'skyblue',\n",
        "    'Light Green': 'lightgreen',\n",
        "    'Light Coral': 'lightcoral',\n",
        "    'White': 'white',\n",
        "    'Black': 'black',\n",
        "    'Red': 'red',\n",
        "    'Green': 'green',\n",
        "    'Navy Blue': 'navy'\n",
        "}\n",
        "\n",
        "# Add color selection to sidebar\n",
        "st.sidebar.header('Color Scheme Selection')\n",
        "selected_color_name = st.sidebar.selectbox('Choose Background Color', list(color_options.keys()))\n",
        "selected_color_hex = color_options[selected_color_name]\n",
        "\n",
        "# --- Custom CSS for background color and text color ---\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp {{ /* Target the main Streamlit application container */\n",
        "        background-color: {selected_color_hex};\n",
        "        color: {'white' if selected_color_name in ['Black', 'Navy Blue', 'Red', 'Green'] else 'black'}; /* Adjust text color for dark backgrounds */\n",
        "    }}\n",
        "    .stMarkdown {{ /* Adjust markdown text color if necessary */\n",
        "        color: {'white' if selected_color_name in ['Black', 'Navy Blue', 'Red', 'Green'] else 'black'};\n",
        "    }}\n",
        "    h1, h2, h3, h4, h5, h6 {{ /* Adjust header text color */\n",
        "        color: {'white' if selected_color_name in ['Black', 'Navy Blue', 'Red', 'Green'] else 'black'};\n",
        "    }}\n",
        "    .stButton {{ /* Adjust button text color */\n",
        "        color: {'white' if selected_color_name in ['Black', 'Navy Blue', 'Red', 'Green'] else 'black'};\n",
        "    }}\n",
        "    /* CSS for left-aligning content in st.dataframe tables */\n",
        "    div[data-testid=\"stDataFrame\"] table th,\n",
        "    div[data-testid=\"stDataFrame\"] table td {{\n",
        "        text-align: left !important;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# 2. Set the main title of the Streamlit application\n",
        "st.title('Direct Marketing Campaigns on Portuguese Banking Data')\n",
        "\n",
        "# Add developer header\n",
        "st.header('Developed by Vaibhav Khare - BITS ID: 2025ab05182@wilp.bits-pilani.ac.in')\n",
        "\n",
        "# Initialize session state variables if they don't exist\n",
        "if 'df_processed' not in st.session_state:\n",
        "    st.session_state['df_processed'] = None\n",
        "if 'X_train' not in st.session_state:\n",
        "    st.session_state['X_train'] = None\n",
        "if 'X_test' not in st.session_state:\n",
        "    st.session_state['X_test'] = None\n",
        "if 'y_train' not in st.session_state:\n",
        "    st.session_state['y_train'] = None\n",
        "if 'y_test' not in st.session_state:\n",
        "    st.session_state['y_test'] = None\n",
        "if 'model' not in st.session_state:\n",
        "    st.session_state['model'] = None\n",
        "if 'y_pred' not in st.session_state:\n",
        "    st.session_state['y_pred'] = None\n",
        "if 'selected_model' not in st.session_state:\n",
        "    st.session_state['selected_model'] = 'Logistic Regression' # Default selection\n",
        "if 'original_df' not in st.session_state: # Initialize original_df\n",
        "    st.session_state['original_df'] = None\n",
        "\n",
        "# --- Data Upload ---\n",
        "st.header('Data Upload - Upload Your Test Data')\n",
        "uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    try:\n",
        "        df = pd.read_csv(uploaded_file)\n",
        "        st.success(\"File uploaded successfully! Here's a preview of your data:\")\n",
        "        st.dataframe(df.head())\n",
        "        st.session_state['original_df'] = df.copy() # Store original for potential re-preprocessing\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading file: {e}\")\n",
        "else:\n",
        "    st.info(\"Please upload a CSV file to get started.\")\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "st.header('Data Preprocessing')\n",
        "if st.session_state['original_df'] is not None:\n",
        "    df = st.session_state['original_df'].copy()\n",
        "\n",
        "    # Convert target variable 'y' from 'yes'/'no' to 1/0\n",
        "    if 'y' in df.columns:\n",
        "        df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
        "        st.write(\"Target variable 'y' converted to numerical (1/0).\")\n",
        "    else:\n",
        "        st.warning(\"Target variable 'y' not found. Ensure the dataset contains a 'y' column.\")\n",
        "\n",
        "    # Identify categorical and numerical columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "    # Remove 'y' from categorical_cols if it's there (after conversion it's numerical)\n",
        "    if 'y' in categorical_cols:\n",
        "        categorical_cols.remove('y')\n",
        "\n",
        "    # Apply one-hot encoding to categorical columns\n",
        "    if categorical_cols:\n",
        "        df_processed = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=int)\n",
        "        st.write(f\"One-hot encoding applied to categorical columns: {', '.join(categorical_cols)}.\")\n",
        "    else:\n",
        "        df_processed = df.copy()\n",
        "        st.info(\"No categorical columns found for one-hot encoding.\")\n",
        "\n",
        "    st.subheader(\"Preprocessed Data Preview:\")\n",
        "    st.dataframe(df_processed.head())\n",
        "    st.session_state['df_processed'] = df_processed\n",
        "\n",
        "# --- Data Splitting ---\n",
        "st.header('Data Splitting')\n",
        "if st.session_state['df_processed'] is not None:\n",
        "    df_processed = st.session_state['df_processed']\n",
        "\n",
        "    if 'y' in df_processed.columns:\n",
        "        X = df_processed.drop('y', axis=1)\n",
        "        y = df_processed['y']\n",
        "        st.write(\"Features (X) and target (y) defined.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        st.write(\"Data split into training and testing sets.\")\n",
        "\n",
        "        st.subheader(\"Shapes of Training and Testing Sets:\")\n",
        "        st.write(f\"X_train shape: {X_train.shape}\")\n",
        "        st.write(f\"y_train shape: {y_train.shape}\")\n",
        "        st.write(f\"X_test shape: {X_test.shape}\")\n",
        "        st.write(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "        st.session_state['X_train'] = X_train\n",
        "        st.session_state['X_test'] = X_test\n",
        "        st.session_state['y_train'] = y_train\n",
        "        st.session_state['y_test'] = y_test\n",
        "\n",
        "    else:\n",
        "        st.error(\"Target variable 'y' not found in the processed DataFrame. Cannot split data.\")\n",
        "\n",
        "# --- Model Selection ---\n",
        "st.sidebar.header('Model Selection')\n",
        "model_options = [\n",
        "    'Logistic Regression',\n",
        "    'Decision Tree Classifier',\n",
        "    'K-Nearest Neighbor Classifier',\n",
        "    'Naive Bayes Classifier (Gaussian Model)',\n",
        "    'Random Forest Model',\n",
        "    'XGBoost Model'\n",
        "]\n",
        "\n",
        "st.session_state['selected_model'] = st.sidebar.selectbox(\n",
        "    'Choose a Classification Model',\n",
        "    model_options,\n",
        "    index=model_options.index(st.session_state['selected_model'])\n",
        ")\n",
        "st.sidebar.write(f\"You selected the **{st.session_state['selected_model']}** model.\")\n",
        "\n",
        "# --- Model Training ---\n",
        "st.header('Model Training')\n",
        "if st.session_state['X_train'] is not None and st.session_state['y_train'] is not None:\n",
        "    X_train = st.session_state['X_train']\n",
        "    y_train = st.session_state['y_train']\n",
        "    X_test = st.session_state['X_test']\n",
        "\n",
        "    if st.button('Train Model'):\n",
        "        st.info(f\"Training {st.session_state['selected_model']}...\")\n",
        "        try:\n",
        "            model = None\n",
        "            if st.session_state['selected_model'] == 'Logistic Regression':\n",
        "                model = LogisticRegression(random_state=42, solver='liblinear')\n",
        "            elif st.session_state['selected_model'] == 'Decision Tree Classifier':\n",
        "                model = DecisionTreeClassifier(random_state=42)\n",
        "            elif st.session_state['selected_model'] == 'K-Nearest Neighbor Classifier':\n",
        "                model = KNeighborsClassifier()\n",
        "            elif st.session_state['selected_model'] == 'Naive Bayes Classifier (Gaussian Model)':\n",
        "                model = GaussianNB()\n",
        "            elif st.session_state['selected_model'] == 'Random Forest Model':\n",
        "                model = RandomForestClassifier(random_state=42)\n",
        "            elif st.session_state['selected_model'] == 'XGBoost Model':\n",
        "                model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')\n",
        "\n",
        "            if model:\n",
        "                model.fit(X_train, y_train)\n",
        "                st.success(f\"{st.session_state['selected_model']} trained successfully!\")\n",
        "                st.session_state['model'] = model\n",
        "                st.session_state['y_pred'] = model.predict(X_test)\n",
        "            else:\n",
        "                st.error(\"No model selected or initialized.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error training model: {e}\")\n",
        "\n",
        "    if st.session_state['model'] is not None:\n",
        "        st.success(\"Model ready for evaluation.\")\n",
        "    else:\n",
        "        st.info(\"Click 'Train Model' to begin.\")\n",
        "else:\n",
        "    st.warning(\"Please upload data and complete preprocessing/splitting steps to train a model.\")\n",
        "\n",
        "# --- Model Evaluation ---\n",
        "st.header('Model Evaluation')\n",
        "if st.session_state['model'] is not None and st.session_state['y_test'] is not None and st.session_state['y_pred'] is not None:\n",
        "    y_test = st.session_state['y_test']\n",
        "    y_pred = st.session_state['y_pred']\n",
        "\n",
        "    if y_test.empty or len(y_pred) == 0:\n",
        "        st.warning(\"y_test or y_pred is empty. Cannot evaluate an empty set.\")\n",
        "    else:\n",
        "        st.write(f\"Evaluating {st.session_state['selected_model']}:\")\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        auc_score = roc_auc_score(y_test, st.session_state['model'].predict_proba(st.session_state['X_test'])[:, 1])\n",
        "        mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "        # Display metrics in a table\n",
        "        metrics_data = {\n",
        "            'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC Score', 'Matthews Correlation Coefficient (MCC)'],\n",
        "            'Value': [accuracy, precision, recall, f1, auc_score, mcc]\n",
        "        }\n",
        "        metrics_df = pd.DataFrame(metrics_data)\n",
        "        st.subheader(\"Evaluation Matrix\")\n",
        "        st.dataframe(metrics_df.set_index('Metric'))\n",
        "\n",
        "        # Display Classification Report\n",
        "        st.subheader(\"Classification Report\")\n",
        "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        st.dataframe(report_df)\n",
        "\n",
        "        # Display Confusion Matrix\n",
        "        st.subheader(\"Confusion Matrix\")\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "        cm_df = pd.DataFrame(cm, index=['Actual Negative (0)', 'Actual Positive (1)'], columns=['Predicted Negative (0)', 'Predicted Positive (1)'])\n",
        "        st.dataframe(cm_df)\n",
        "else:\n",
        "    st.warning(\"Please train a model to see evaluation metrics.\")\n",
        "\n",
        "# --- Reset Button ---\n",
        "st.sidebar.markdown('---')\n",
        "if st.sidebar.button('Clear Results and Reset'):\n",
        "    for key in st.session_state.keys():\n",
        "        del st.session_state[key]\n",
        "    st.rerun()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ad03df8",
        "outputId": "a75f546b-0419-4f03-de34-33d4180d51c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.204.203.14:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}